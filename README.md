# CS189_HW1
### Guidance on how to run my code 
## Question 2: 
-  To generate the "SVM Decision Boundary and Margins with Support Vectors" plot, run the subsequent cells under "2e_Theory of Hard-Margin Support Vector Machines" in the hw1_code.ipynb Jupyter Notebook. 
##  Question 3:
- **3a**) Data partitioning code can be run by running the cell directly under the "3a_Data Partitioning, TODO: reshuffle the data".
- **3b)** The Evaluation Metric code can be run by running the cell directly under the "3b_Evaluation Metric."
##  Question 4:
- **Part 1:** Run the cell directly under "4_Support Vector Machines: Coding" to generate the training and validation accuracy, as well as the plot for "MNIST Dataset: Training Accuracy and Validation Accuracy vs Number of Examples".
- **Part 2:** Run the cell directly under the previous cell to generate the training and validation accuracy and the plot for "Spam Dataset: Training Accuracy and Validation Accuracy vs Number of Examples".
##  Question 5:
- Run the cell directly under "5_Hyperparameter Tuning", it outputs each C value's validation accuracy & retrains a LinearSVC model on all of the MNIST training data, and makes predictions on the MNIST test set.
##  Question 6:
- Run the cell directly under "6_K Fold Cross Validation", it outputs each C value's average validation accuracies and the best C value.
##  Question 7:
- Kaggle code script for MNIST dataset in the **MNIST_kaggle.py** file, cd into the hw1 folder, and in this directory run the command on the terminal "python MNIST_kaggle.py"
- Kaggle code script for SPAM dataset in the **SPAM_kaggle.py** file, cd into the hw1 folder, and in this directory run the command on the terminal "python SPAM_kaggle.py"
